{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9afdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Type hints.\n",
    "from typing import List, Tuple\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "348843ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from pytorch101.py!\n"
     ]
    }
   ],
   "source": [
    "def hello():\n",
    "    \"\"\"\n",
    "    This is a sample function that we will try to import and run to ensure that\n",
    "    our environment is correctly set up on Google Colab.\n",
    "    \"\"\"\n",
    "    print('Hello from pytorch101.py!')\n",
    "hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37a1058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_tensor() -> Tensor:\n",
    "    \"\"\"\n",
    "    Return a torch Tensor of shape (3, 2) which is filled with zeros, except\n",
    "    for element (0, 1) which is set to 10 and element (1, 0) which is set to\n",
    "    100.\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape (3, 2) as described above.\n",
    "    \"\"\"\n",
    "    x = None\n",
    "    ##########################################################################\n",
    "    #                     TODO: Implement this function                      #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    x = torch.zeros(3, 2)\n",
    "    x[0, 1] = 10\n",
    "    x[1, 0] = 100\n",
    "    ###########################################################################\n",
    "    #                            END OF YOUR CODE                             #\n",
    "    ###########################################################################\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae8f6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,  10.],\n",
       "        [100.,   0.],\n",
       "        [  0.,   0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_sample_tensor()  #呼叫函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c77053cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_tensor(\n",
    "    x: Tensor, indices: List[Tuple[int, int]], values: List[float]\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Mutate the tensor x according to indices and values. Specifically, indices\n",
    "    is a list [(i0, j0), (i1, j1), ... ] of integer indices, and values is a\n",
    "    list [v0, v1, ...] of values. This function should mutate x by setting:\n",
    "\n",
    "    x[i0, j0] = v0\n",
    "    x[i1, j1] = v1\n",
    "\n",
    "    and so on.\n",
    "\n",
    "    If the same index pair appears multiple times in indices, you should set x\n",
    "    to the last one.\n",
    "\n",
    "    Args:\n",
    "        x: A Tensor of shape (H, W)\n",
    "        indices: A list of N tuples [(i0, j0), (i1, j1), ..., ]\n",
    "        values: A list of N values [v0, v1, ...]\n",
    "\n",
    "    Returns:\n",
    "        The input tensor x\n",
    "    \"\"\"\n",
    "    ##########################################################################\n",
    "    #                     TODO: Implement this function                      #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    x = x.float()\n",
    "    for index, value in enumerate(indices):\n",
    "        x[value[0], value[1]] = values[index]\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "763a4859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100.0000,   2.0000,   3.0000],\n",
       "        [  4.0000,   5.0000,   0.5000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3],                    \n",
    "                  [4, 5, 6]])                  \n",
    "mutate_tensor(x, [(0, 0), (1, 2)], [100, 0.5])  #將x矩陣位置(0, 0)的值設定為100\n",
    "                                                #將x矩陣位置(1, 2)的值設定為0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e63baa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100.0000,   2.0000,   3.0000],\n",
       "        [  4.0000,   5.0000,   0.5000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no x.float()\n",
    "x = torch.tensor([[1, 2, 3],                    \n",
    "                  [4, 5, 6]])                  \n",
    "mutate_tensor(x, [(0, 0), (1, 2)], [100, 0.5])  #將x矩陣位置(0, 0)的值設定為100\n",
    "                                                #將x矩陣位置(1, 2)的值設定為0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f841af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tensor_elements(x: Tensor) -> int:\n",
    "    \"\"\"\n",
    "    Count the number of scalar elements in a tensor x.\n",
    "\n",
    "    For example, a tensor of shape (10,) has 10 elements; a tensor of shape\n",
    "    (3, 4) has 12 elements; a tensor of shape (2, 3, 4) has 24 elements, etc.\n",
    "\n",
    "    You may not use the functions torch.numel or x.numel. The input tensor\n",
    "    should not be modified.\n",
    "\n",
    "    Args:\n",
    "        x: A tensor of any shape\n",
    "\n",
    "    Returns:\n",
    "        num_elements: An integer giving the number of scalar elements in x\n",
    "    \"\"\"\n",
    "    num_elements = None\n",
    "    ##########################################################################\n",
    "    #                      TODO: Implement this function                     #\n",
    "    #   You CANNOT use the built-in functions torch.numel(x) or x.numel().   #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    num_elements = 1\n",
    "    for dim in x.shape:\n",
    "        # print(dim)\n",
    "        num_elements *= dim\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return num_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0724bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tensor of shape (10, ) has 10 elements\n",
      "a tensor of shape (3, 4) has 12 elements\n",
      "a tensor of shape (2, 3, 4) has 24 elements\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(10,)\n",
    "print(f\"a tensor of shape (10, ) has {count_tensor_elements(x)} elements\")\n",
    "\n",
    "x = torch.ones(3, 4)\n",
    "print(f\"a tensor of shape (3, 4) has {count_tensor_elements(x)} elements\")\n",
    "\n",
    "x = torch.ones(2, 3, 4)\n",
    "print(f\"a tensor of shape (2, 3, 4) has {count_tensor_elements(x)} elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6f3db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor_of_pi(M: int, N: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Returns a Tensor of shape (M, N) filled entirely with the value 3.14\n",
    "\n",
    "    Args:\n",
    "        M, N: Positive integers giving the shape of Tensor to create\n",
    "\n",
    "    Returns:\n",
    "        x: A tensor of shape (M, N) filled with the value 3.14\n",
    "    \"\"\"\n",
    "    x = None\n",
    "    ##########################################################################\n",
    "    #         TODO: Implement this function. It should take one line.        #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    x = 3.14 * torch.ones(M, N)\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e8f12b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1400, 3.1400],\n",
       "        [3.1400, 3.1400],\n",
       "        [3.1400, 3.1400]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_tensor_of_pi(3, 2)  #產生(3, 2)且元素皆為3.14的矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df35831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiples_of_ten(start: int, stop: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Returns a Tensor of dtype torch.float64 that contains all of the multiples\n",
    "    of ten (in order) between start and stop, inclusive. If there are no\n",
    "    multiples of ten in this range then return an empty tensor of shape (0,).\n",
    "\n",
    "    Args:\n",
    "        start: Beginning ot range to create.\n",
    "        stop: End of range to create (stop >= start).\n",
    "\n",
    "    Returns:\n",
    "        x: float64 Tensor giving multiples of ten between start and stop\n",
    "    \"\"\"\n",
    "    assert start <= stop\n",
    "    x = None\n",
    "    ##########################################################################\n",
    "    #                      TODO: Implement this function                     #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    result = [x for x in range(start, stop+1) if x % 10 == 0]\n",
    "    x = torch.tensor(result, dtype=torch.float64)\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e07c38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 10.,  20.,  30.,  40.,  50.,  60.,  70.,  80.,  90., 100., 110., 120.,\n",
       "        130., 140., 150., 160., 170., 180., 190., 200.], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiples_of_ten(10, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1ad3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_indexing_practice(x: Tensor) -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
    "\"\"\"\n",
    "    Given a two-dimensional tensor x, extract and return several subtensors to\n",
    "    practice with slice indexing. Each tensor should be created using a single\n",
    "    slice indexing operation.\n",
    "\n",
    "    The input tensor should not be modified.\n",
    "\n",
    "    Args:\n",
    "        x: Tensor of shape (M, N) -- M rows, N columns with M >= 3 and N >= 5.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of:\n",
    "        - last_row: Tensor of shape (N,) giving the last row of x. It should be\n",
    "          a one-dimensional tensor.\n",
    "        - third_col: Tensor of shape (M, 1) giving the third column of x. It\n",
    "          should be a two-dimensional tensor.\n",
    "        - first_two_rows_three_cols: Tensor of shape (2, 3) giving the data in\n",
    "          the first two rows and first three columns of x.\n",
    "        - even_rows_odd_cols: Two-dimensional tensor containing the elements in\n",
    "          the even-valued rows and odd-valued columns of x.\n",
    "    \"\"\"\n",
    "    assert x.shape[0] >= 3\n",
    "    assert x.shape[1] >= 5\n",
    "    last_row =None\n",
    "    third_col = None\n",
    "    first_two_rows_three_cols = None\n",
    "    even_rows_odd_cols = None\n",
    "    ##########################################################################\n",
    "    #                      TODO: Implement this function                     #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    last_row = x[-1]\n",
    "    third_col = x[:, 2:3]\n",
    "    first_two_rows_three_cols = x[0:2, 0:3]\n",
    "    even_rows_odd_cols = x[::2, 1::2]\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    out = (\n",
    "        last_row,\n",
    "        third_col,\n",
    "        first_two_rows_three_cols,\n",
    "        even_rows_odd_cols,\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fde876e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([16, 17, 18, 19, 20]),\n",
       " tensor([[ 3],\n",
       "         [ 8],\n",
       "         [13],\n",
       "         [18]]),\n",
       " tensor([[1, 2, 3],\n",
       "         [6, 7, 8]]),\n",
       " tensor([[ 2,  4],\n",
       "         [12, 14]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4, 5],\n",
    "                  [6, 7, 8, 9, 10],\n",
    "                  [11, 12, 13, 14, 15],\n",
    "                  [16, 17, 18, 19, 20]])\n",
    "slice_indexing_practice(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4731450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_assignment_practice(x: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Given a two-dimensional tensor of shape (M, N) with M >= 4, N >= 6, mutate\n",
    "    its first 4 rows and 6 columns so they are equal to:\n",
    "\n",
    "    [0 1 2 2 2 2]\n",
    "    [0 1 2 2 2 2]\n",
    "    [3 4 3 4 5 5]\n",
    "    [3 4 3 4 5 5]\n",
    "\n",
    "    Note: the input tensor shape is not fixed to (4, 6).\n",
    "\n",
    "    Your implementation must obey the following:\n",
    "    - You should mutate the tensor x in-place and return it\n",
    "    - You should only modify the first 4 rows and first 6 columns; all other\n",
    "      elements should remain unchanged\n",
    "    - You may only mutate the tensor using slice assignment operations, where\n",
    "      you assign an integer to a slice of the tensor\n",
    "    - You must use <= 6 slicing operations to achieve the desired result\n",
    "\n",
    "    Args:\n",
    "        x: A tensor of shape (M, N) with M >= 4 and N >= 6\n",
    "\n",
    "    Returns:\n",
    "        x\n",
    "    \"\"\"\n",
    "    ##########################################################################\n",
    "    #                      TODO: Implement this function                     #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    replace = torch.tensor([[0, 1, 2, 2, 2, 2],\n",
    "                            [0, 1, 2, 2, 2, 2],\n",
    "                            [3, 4, 3, 4, 5, 5],\n",
    "                            [3, 4, 3, 4, 5, 5]])\n",
    "    x[0:4, 0:6] = replace\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db0aedcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 2., 2., 2., 0., 0.],\n",
       "        [0., 1., 2., 2., 2., 2., 0., 0.],\n",
       "        [3., 4., 3., 4., 5., 5., 0., 0.],\n",
       "        [3., 4., 3., 4., 5., 5., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(8, 8)\n",
    "slice_assignment_practice(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99dfa600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_cols(x: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Re-order the columns of an input tensor as described below.\n",
    "\n",
    "    Your implementation should construct the output tensor using a single\n",
    "    integer array indexing operation. The input tensor should not be modified.\n",
    "\n",
    "    Args:\n",
    "        x: A tensor of shape (M, N) with N >= 3\n",
    "\n",
    "    Returns:\n",
    "        A tensor y of shape (M, 4) where:\n",
    "        - The first two columns of y are copies of the first column of x\n",
    "        - The third column of y is the same as the third column of x\n",
    "        - The fourth column of y is the same as the second column of x\n",
    "    \"\"\"\n",
    "    y = None\n",
    "    ##########################################################################\n",
    "    #                      TODO: Implement this function                     #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    y = x[:, (0, 0, 2, 1)]\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cabff00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1,  3,  2],\n",
       "        [ 6,  6,  8,  7],\n",
       "        [11, 11, 13, 12],\n",
       "        [16, 16, 18, 17]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4, 5],\n",
    "                  [6, 7, 8, 9, 10],\n",
    "                  [11, 12, 13, 14, 15],\n",
    "                  [16, 17, 18, 19, 20]])\n",
    "shuffle_cols(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16438624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_rows(x: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Reverse the rows of the input tensor.\n",
    "\n",
    "    Your implementation should construct the output tensor using a single\n",
    "    integer array indexing operation. The input tensor should not be modified.\n",
    "\n",
    "    Your implementation may not use torch.flip.\n",
    "\n",
    "    Args:\n",
    "        x: A tensor of shape (M, N)\n",
    "\n",
    "    Returns:\n",
    "        y: Tensor of shape (M, N) which is the same as x but with the rows\n",
    "            reversed - the first row of y should be equal to the last row of x,\n",
    "            the second row of y should be equal to the second to last row of x,\n",
    "            and so on.\n",
    "    \"\"\"\n",
    "    y = None\n",
    "    ##########################################################################\n",
    "    #                      TODO: Implement this function                     #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    y = torch.flip(x, [0])\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "858f7b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16, 17, 18, 19, 20],\n",
       "        [11, 12, 13, 14, 15],\n",
       "        [ 6,  7,  8,  9, 10],\n",
       "        [ 1,  2,  3,  4,  5]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4, 5],\n",
    "                  [6, 7, 8, 9, 10],\n",
    "                  [11, 12, 13, 14, 15],\n",
    "                  [16, 17, 18, 19, 20]])\n",
    "reverse_rows(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb27712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_one_elem_per_col(x: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Construct a new tensor by picking out one element from each column of the\n",
    "    input tensor as described below.\n",
    "\n",
    "    The input tensor should not be modified, and you should only access the\n",
    "    data of the input tensor using a single indexing operation.\n",
    "\n",
    "    Args:\n",
    "        x: A tensor of shape (M, N) with M >= 4 and N >= 3.\n",
    "\n",
    "    Returns:\n",
    "        A tensor y of shape (3,) such that:\n",
    "        - The first element of y is the second element of the first column of x\n",
    "        - The second element of y is the first element of the second column of x\n",
    "        - The third element of y is the fourth element of the third column of x\n",
    "    \"\"\"\n",
    "    y = None\n",
    "    ##########################################################################\n",
    "    #                      TODO: Implement this function                     #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    y = x[(1, 0, 3), (0, 1, 2)]\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ac0fa22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  2, 18])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4, 5],\n",
    "                  [6, 7, 8, 9, 10],\n",
    "                  [11, 12, 13, 14, 15],\n",
    "                  [16, 17, 18, 19, 20]])\n",
    "take_one_elem_per_col(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "963018f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot(x: List[int]) -> Tensor:\n",
    "    \"\"\"\n",
    "    Construct a tensor of one-hot-vectors from a list of Python integers.\n",
    "\n",
    "    Your implementation should not use any Python loops (including\n",
    "    comprehensions).\n",
    "\n",
    "    Args:\n",
    "        x: A list of N integers\n",
    "\n",
    "    Returns:\n",
    "        y: Tensor of shape (N, C) and where C = 1 + max(x) is one more than the\n",
    "            max value in x. The nth row of y is a one-hot-vector representation\n",
    "            of x[n]; in other words, if x[n] = c then y[n, c] = 1; all other\n",
    "            elements of y are zeros. The dtype of y should be torch.float32.\n",
    "    \"\"\"\n",
    "    y = None\n",
    "    ##########################################################################\n",
    "    #                      TODO: Implement this function                     #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    C = 1 + max(x)\n",
    "    N = len(x)\n",
    "    y = torch.zeros(N, C)\n",
    "    \n",
    "    for n, c in enumerate(x):\n",
    "        y[n, c] = 1\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6af09a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list([0, 2, 1, 4, 3])\n",
    "make_one_hot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7b1e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_positive_entries(x: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Return the sum of all the positive values in the input tensor x.\n",
    "\n",
    "    For example, given the input tensor\n",
    "\n",
    "    x = [[ -1   2   0 ],\n",
    "         [  0   5  -3 ],\n",
    "         [  8  -9   0 ]]\n",
    "\n",
    "    This function should return sum_positive_entries(x) = 2 + 5 + 8 = 15\n",
    "\n",
    "    Your output should be a Python integer, *not* a PyTorch scalar.\n",
    "\n",
    "    Your implementation should not modify the input tensor, and should not use\n",
    "    any explicit Python loops (including comprehensions). You should access\n",
    "    the data of the input tensor using only a single comparison operation and a\n",
    "    single indexing operation.\n",
    "\n",
    "    Args:\n",
    "        x: A tensor of any shape with dtype torch.int64\n",
    "\n",
    "    Returns:\n",
    "        pos_sum: Python integer giving the sum of all positive values in x\n",
    "    \"\"\"\n",
    "    pos_sum = None\n",
    "    ##########################################################################\n",
    "    #                      TODO: Implement this function                     #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    pos_value = x[x>0]\n",
    "    pos_sum = torch.sum(pos_value)\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return pos_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ecb4429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[-1, 2, 0],\n",
    "     [0, 5, -3],\n",
    "     [8, -9, 0]])\n",
    "sum_positive_entries(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc5bdf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_practice(x: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Given an input tensor of shape (24,), return a reshaped tensor y of shape\n",
    "    (3, 8) such that\n",
    "\n",
    "    y = [[x[0], x[1], x[2],  x[3],  x[12], x[13], x[14], x[15]],\n",
    "         [x[4], x[5], x[6],  x[7],  x[16], x[17], x[18], x[19]],\n",
    "         [x[8], x[9], x[10], x[11], x[20], x[21], x[22], x[23]]]\n",
    "\n",
    "    You must construct y by performing a sequence of reshaping operations on\n",
    "    x (view, t, transpose, permute, contiguous, reshape, etc). The input\n",
    "    tensor should not be modified.\n",
    "\n",
    "    Args:\n",
    "        x: A tensor of shape (24,)\n",
    "\n",
    "    Returns:\n",
    "        y: A reshaped version of x of shape (3, 8) as described above.\n",
    "    \"\"\"\n",
    "    y = None\n",
    "    ##########################################################################\n",
    "    #                      TODO: Implement this function                     #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    y = x.view(2, 3, 4)\n",
    "    y = torch.cat((y[0,:,:], y[1, :, :]), dim = 1)\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "036084c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3, 12, 13, 14, 15],\n",
       "        [ 4,  5,  6,  7, 16, 17, 18, 19],\n",
       "        [ 8,  9, 10, 11, 20, 21, 22, 23]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(24)\n",
    "reshape_practice(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cae8e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_row_min(x: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Return a copy of the input tensor x, where the minimum value along each row\n",
    "    has been set to 0.\n",
    "\n",
    "    For example, if x is:\n",
    "    x = torch.tensor([\n",
    "          [10, 20, 30],\n",
    "          [ 2,  5,  1]])\n",
    "\n",
    "    Then y = zero_row_min(x) should be:\n",
    "    torch.tensor([\n",
    "        [0, 20, 30],\n",
    "        [2,  5,  0]\n",
    "    ])\n",
    "\n",
    "    Your implementation shoud use reduction and indexing operations. You should\n",
    "    not use any Python loops (including comprehensions). The input tensor\n",
    "    should not be modified.\n",
    "\n",
    "    Args:\n",
    "        x: Tensor of shape (M, N)\n",
    "\n",
    "    Returns:\n",
    "        y: Tensor of shape (M, N) that is a copy of x, except the minimum value\n",
    "            along each row is replaced with 0.\n",
    "    \"\"\"\n",
    "    y = None\n",
    "    ##########################################################################\n",
    "    #                      TODO: Implement this function                     #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    y = x.clone()\n",
    "    min_index = torch.argmin(x, dim=1)\n",
    "    index = torch.arange(x.shape[0])\n",
    "    y[index, min_index] = 0\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb090f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 20, 30],\n",
       "        [ 2,  5,  0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[10, 20, 30],\n",
    "                  [ 2,  5,  1]])\n",
    "zero_row_min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1fea4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_matrix_multiply(\n",
    "    x: Tensor, y: Tensor, use_loop: bool = True\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Perform batched matrix multiplication between the tensor x of shape\n",
    "    (B, N, M) and the tensor y of shape (B, M, P).\n",
    "\n",
    "    Depending on the value of use_loop, this calls to either\n",
    "    batched_matrix_multiply_loop or batched_matrix_multiply_noloop to perform\n",
    "    the actual computation. You don't need to implement anything here.\n",
    "\n",
    "    Args:\n",
    "        x: Tensor of shape (B, N, M)\n",
    "        y: Tensor of shape (B, M, P)\n",
    "        use_loop: Whether to use an explicit Python loop.\n",
    "\n",
    "    Returns:\n",
    "        z: Tensor of shape (B, N, P) where z[i] of shape (N, P) is the result\n",
    "            of matrix multiplication between x[i] of shape (N, M) and y[i] of\n",
    "            shape (M, P). The output z should have the same dtype as x.\n",
    "    \"\"\"\n",
    "    if use_loop:\n",
    "        return batched_matrix_multiply_loop(x, y)\n",
    "    else:\n",
    "        return batched_matrix_multiply_noloop(x, y)\n",
    "\n",
    "\n",
    "def batched_matrix_multiply_loop(x: Tensor, y: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Perform batched matrix multiplication between the tensor x of shape\n",
    "    (B, N, M) and the tensor y of shape (B, M, P).\n",
    "\n",
    "    This implementation should use a single explicit loop over the batch\n",
    "    dimension B to compute the output.\n",
    "\n",
    "    Args:\n",
    "        x: Tensor of shaper (B, N, M)\n",
    "        y: Tensor of shape (B, M, P)\n",
    "\n",
    "    Returns:\n",
    "        z: Tensor of shape (B, N, P) where z[i] of shape (N, P) is the result\n",
    "            of matrix multiplication between x[i] of shape (N, M) and y[i] of\n",
    "            shape (M, P). The output z should have the same dtype as x.\n",
    "    \"\"\"\n",
    "    z = None\n",
    "    ###########################################################################\n",
    "    #                      TODO: Implement this function                      #\n",
    "    ###########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    z = torch.zeros(size=(x.shape[0], x.shape[1], y.shape[2]))\n",
    "    for i in range(y.shape[0]):\n",
    "        z[i] = torch.mm(x[i], y[i])\n",
    "    ###########################################################################\n",
    "    #                           END OF YOUR CODE                              #\n",
    "    ###########################################################################\n",
    "    return z\n",
    "\n",
    "\n",
    "def batched_matrix_multiply_noloop(x: Tensor, y: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Perform batched matrix multiplication between the tensor x of shape\n",
    "    (B, N, M) and the tensor y of shape (B, M, P).\n",
    "\n",
    "    This implementation should use no explicit Python loops (including\n",
    "    comprehensions).\n",
    "\n",
    "    Hint: torch.bmm\n",
    "\n",
    "    Args:\n",
    "        x: Tensor of shaper (B, N, M)\n",
    "        y: Tensor of shape (B, M, P)\n",
    "\n",
    "    Returns:\n",
    "        z: Tensor of shape (B, N, P) where z[i] of shape (N, P) is the result\n",
    "            of matrix multiplication between x[i] of shape (N, M) and y[i] of\n",
    "            shape (M, P). The output z should have the same dtype as x.\n",
    "    \"\"\"\n",
    "    z = None\n",
    "    ###########################################################################\n",
    "    #                      TODO: Implement this function                      #\n",
    "    ###########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    z = torch.bmm(x, y)\n",
    "    ###########################################################################\n",
    "    #                            END OF YOUR CODE                             #\n",
    "    ###########################################################################\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5fa847c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of using loop is tensor([[[ 30.,  34.,  38.,  42.,  46.],\n",
      "         [ 30.,  34.,  38.,  42.,  46.],\n",
      "         [ 30.,  34.,  38.,  42.,  46.]],\n",
      "\n",
      "        [[110., 114., 118., 122., 126.],\n",
      "         [110., 114., 118., 122., 126.],\n",
      "         [110., 114., 118., 122., 126.]]])\n",
      "The result of not using loop is tensor([[[ 30.,  34.,  38.,  42.,  46.],\n",
      "         [ 30.,  34.,  38.,  42.,  46.],\n",
      "         [ 30.,  34.,  38.,  42.,  46.]],\n",
      "\n",
      "        [[110., 114., 118., 122., 126.],\n",
      "         [110., 114., 118., 122., 126.],\n",
      "         [110., 114., 118., 122., 126.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(size=(2, 3, 4))\n",
    "y = torch.arange(0, 40, dtype=torch.float).reshape(shape=(2, 4, 5))\n",
    "\n",
    "z_loop = batched_matrix_multiply(x, y, use_loop=True)\n",
    "print(f\"The result of using loop is {z_loop}\")\n",
    "\n",
    "z_noloop = batched_matrix_multiply(x, y, use_loop=False)\n",
    "print(f\"The result of not using loop is {z_noloop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76bfbdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(x: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Normalize the columns of the matrix x by subtracting the mean and dividing\n",
    "    by standard deviation of each column. You should return a new tensor; the\n",
    "    input should not be modified.\n",
    "\n",
    "    More concretely, given an input tensor x of shape (M, N), produce an output\n",
    "    tensor y of shape (M, N) where y[i, j] = (x[i, j] - mu_j) / sigma_j, where\n",
    "    mu_j is the mean of the column x[:, j].\n",
    "\n",
    "    Your implementation should not use any explicit Python loops (including\n",
    "    comprehensions); you may only use basic arithmetic operations on tensors\n",
    "    (+, -, *, /, **, sqrt), the sum reduction function, and reshape operations\n",
    "    to facilitate broadcasting. You should not use torch.mean, torch.std, or\n",
    "    their instance method variants x.mean, x.std.\n",
    "\n",
    "    Args:\n",
    "        x: Tensor of shape (M, N).\n",
    "\n",
    "    Returns:\n",
    "        y: Tensor of shape (M, N) as described above. It should have the same\n",
    "            dtype as the input x.\n",
    "    \"\"\"\n",
    "    y = None\n",
    "    ##########################################################################\n",
    "    #                      TODO: Implement this function                     #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    y = x.clone()\n",
    "    mu_j = y.sum(dim=0) / y.shape[0]\n",
    "    sigma_j = torch.sqrt(((y - mu_j)**2).sum(dim=0) / y.shape[0])\n",
    "    y = (y - mu_j) / sigma_j\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a08dc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2247, -1.2247, -1.2247],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 1.2247,  1.2247,  1.2247]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [2, 4, 6],\n",
    "                  [3, 6, 9]])  \n",
    "# the mean of the columns are (2, 4, 6)\n",
    "# the std of the columns are (0.8165, 1.633, 2.45)\n",
    "normalize_columns(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cc7dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm_on_cpu(x: Tensor, w: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Perform matrix multiplication on CPU.\n",
    "\n",
    "    You don't need to implement anything for this function.\n",
    "\n",
    "    Args:\n",
    "        x: Tensor of shape (A, B), on CPU\n",
    "        w: Tensor of shape (B, C), on CPU\n",
    "\n",
    "    Returns:\n",
    "        y: Tensor of shape (A, C) as described above. It should not be in GPU.\n",
    "    \"\"\"\n",
    "    y = x.mm(w)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2f27df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm_on_gpu(x: Tensor, w: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Perform matrix multiplication on GPU.\n",
    "\n",
    "    Specifically, given two input tensors this function should:\n",
    "    (1) move each input tensor to the GPU;\n",
    "    (2) perform matrix multiplication between the GPU tensors;\n",
    "    (3) move the result back to CPU\n",
    "\n",
    "    When you move the tensor to GPU, use the \"your_tensor.cuda()\" operation\n",
    "\n",
    "    Args:\n",
    "        x: Tensor of shape (A, B), on CPU\n",
    "        w: Tensor of shape (B, C), on CPU\n",
    "\n",
    "    Returns:\n",
    "        y: Tensor of shape (A, C) as described above. It should not be in GPU.\n",
    "    \"\"\"\n",
    "    y = None\n",
    "    ##########################################################################\n",
    "    #                      TODO: Implement this function                     #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    x = x.float()\n",
    "    w = w.float()\n",
    "    x_gpu = x.cuda()\n",
    "    w_gpu = w.cuda()\n",
    "    y_gpu = torch.matmul(x_gpu, w_gpu)\n",
    "    y = y_gpu.cpu()\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5bdb7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [15., 15., 15.],\n",
       "        [24., 24., 24.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "w = torch.ones(size=(3, 3))\n",
    "mm_on_gpu(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcc4726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "407c0258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def challenge_mean_tensors(xs: List[Tensor], ls: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    Compute mean of each tensor in a given list of tensors.\n",
    "\n",
    "    Specifically, the input is a list of N tensors, (1 <= N <= 10000). The i-th\n",
    "    tensor in this list has length Ki, (1 <= Ki <= 10000). Return a tensor of\n",
    "    shape (N, ) whose i-th element gives the mean of i-th tensor in input list.\n",
    "    You may assume that all tensors are on the same device (CPU or GPU).\n",
    "\n",
    "    Your implementation should not use any explicit Python loops (including\n",
    "    comprehensions).\n",
    "\n",
    "    Args:\n",
    "        xs: List of N 1-dimensional tensors.\n",
    "        ls: Length of tensors in `xs`. An int64 Tensor of same length as `xs`\n",
    "            with `ls[i]` giving the length of `xs[i]`.\n",
    "\n",
    "    Returns:\n",
    "        y: Tensor of shape (N, ) with `y[i]` giving the mean of `xs[i]`.\n",
    "    \"\"\"\n",
    "\n",
    "    y = None\n",
    "    ##########################################################################\n",
    "    # TODO: Implement this function without using `for` loops and store the  #\n",
    "    # mean values as a tensor in `y`.                                        #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    y = torch.stack([torch.sum(x) for x in xs])\n",
    "    ls = torch.tensor(ls)\n",
    "    y = y / ls\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48e18388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first tensor in xs is tensor([1, 2, 3]), with mean = 2\n",
      "the first tensor in xs is tensor([1, 1, 1, 2, 2, 2]), with mean = 1.5\n",
      "the first tensor in xs is tensor([1, 1, 1, 2, 2, 2]), with mean = 2.5\n",
      "\n",
      "result of challenge_mean_tensors(xs, ls) is tensor([2.0000, 1.5000, 2.5000])\n",
      "\n",
      "the mean of the first tensor in xs is correct: True\n",
      "the mean of the second tensor in xs is correct: True\n",
      "the mean of the third tensor in xs is correct: True\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor([1, 2, 3])              #x1's mean = 2\n",
    "x2 = torch.tensor([1, 1, 1, 2, 2, 2])     #x2's mean = 1.5\n",
    "x3 = torch.tensor([1.5, 2, 2.5, 3, 3.5])  #x3's mean = 2.5\n",
    "xs = [x1, x2, x3]\n",
    "ls = [3, 6, 5]\n",
    "\n",
    "print(f\"the first tensor in xs is {xs[0]}, with mean = 2\")\n",
    "print(f\"the first tensor in xs is {xs[1]}, with mean = 1.5\")\n",
    "print(f\"the first tensor in xs is {xs[1]}, with mean = 2.5\")\n",
    "print(\"\")\n",
    "print(f\"result of challenge_mean_tensors(xs, ls) is {challenge_mean_tensors(xs, ls)}\")\n",
    "print(\"\")\n",
    "print(f\"the mean of the first tensor in xs is correct: {challenge_mean_tensors(xs, ls)[0] == 2}\")\n",
    "print(f\"the mean of the second tensor in xs is correct: {challenge_mean_tensors(xs, ls)[1] == 1.5}\")\n",
    "print(f\"the mean of the third tensor in xs is correct: {challenge_mean_tensors(xs, ls)[2] == 2.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6a0358af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def challenge_get_uniques(x: torch.Tensor) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Get unique values and first occurrence from an input tensor.\n",
    "\n",
    "    Specifically, the input is 1-dimensional int64 Tensor with length N. This\n",
    "    tensor contains K unique values (not necessarily consecutive). Your\n",
    "    implementation must return two tensors:\n",
    "    1. uniques: int64 Tensor of shape (K, ) - giving K uniques from input.\n",
    "    2. indices: int64 Tensor of shape (K, ) - giving indices of the first\n",
    "       occurring unique values.\n",
    "\n",
    "    Concretely, this should hold True: x[indices[i]] = uniques[i] \n",
    "\n",
    "    Your implementation should not use any explicit Python loops (including\n",
    "    comprehensions), and should not require more than O(N) memory. Creating\n",
    "    new tensors larger than input tensor is not allowed. If you wish to\n",
    "    create new tensors like input tensor, use `input.clone()`.\n",
    "\n",
    "    You may use `torch.unique`, but you will receive half credit for that.\n",
    "\n",
    "    Args:\n",
    "        x: Tensor of shape (N, ) with K <= N unique values.\n",
    "\n",
    "    Returns:\n",
    "        uniques and indices: Se description above.\n",
    "    \"\"\"\n",
    "\n",
    "    uniques, indices = None, None\n",
    "    ##########################################################################\n",
    "    # TODO: Implement this function without using `for` loops and within     #\n",
    "    # O(N) memory.                                                           #\n",
    "    ##########################################################################\n",
    "    # Replace \"pass\" statement with your code\n",
    "    sorted_indices = torch.argsort(x)\n",
    "    sorted_tensor = x[sorted_indices]\n",
    "    \n",
    "    unique_mask = torch.cat((torch.tensor([True]), sorted_tensor[1:] != sorted_tensor[:-1]), dim=0)\n",
    "    # print(unique_mask)\n",
    "    indices = sorted_indices[unique_mask]\n",
    "    uniques = x[indices]\n",
    "    ##########################################################################\n",
    "    #                            END OF YOUR CODE                            #\n",
    "    ##########################################################################\n",
    "    return uniques, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fd877c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([1, 2, 1, 2, 3, 2])\n",
      "unique numbers are 1, 2, 3\n",
      "the indices of the unique numbers are 0, 1, 4\n",
      "\n",
      "Result of challenge_get_uniques: \n",
      "unique numbers = tensor([1, 2, 3])\n",
      "indices of the numbers are tensor([0, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 1, 2, 3, 2])\n",
    "print(f\"x = {x}\")\n",
    "print(f\"unique numbers are 1, 2, 3\")\n",
    "print(f\"the indices of the unique numbers are 0, 1, 4\\n\")\n",
    "print(f\"Result of challenge_get_uniques: \")\n",
    "print(f\"unique numbers = {challenge_get_uniques(x)[0]}\")\n",
    "print(f\"indices of the numbers are {challenge_get_uniques(x)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21abaee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
